{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DUMAY_KALLEL_3Models.ipynb","provenance":[],"collapsed_sections":["YzLlLVkv5vfq"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lmjEa0qd4QHt","colab_type":"text"},"source":["# Prediction of music listening (Part III): Models\n","\n","In this notebook, we are applying different models of Machine Learning to the pre-processed data. The first step is to retrieve latent factors from the previous notebook. (If you want, we can provide you the files)\n","\n","In the first section, we are using TensorFlow to run the model. Then, we use a boosting algorithm called XGBoost."]},{"cell_type":"markdown","metadata":{"id":"KKx2iHbuo3Hc","colab_type":"text"},"source":["## Retrieving data"]},{"cell_type":"code","metadata":{"id":"WWgw-e7pXztD","colab_type":"code","outputId":"93dc4dae-e1d0-4b33-eac4-3c2297b4dd5c","executionInfo":{"status":"ok","timestamp":1579193039316,"user_tz":-60,"elapsed":37775,"user":{"displayName":"alice dumay","photoUrl":"","userId":"10230404805774338260"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["# Links this notebook with a Google Drive account on which data will be stored\n","from google.colab import drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JTCUhCesYRK3","colab_type":"code","colab":{}},"source":["# Import data from the linked Google Drive account\n","!cp 'drive/My Drive/train_latent.p' .\n","!cp 'drive/My Drive/test_latent.p' ."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXW3LdEV44dV","colab_type":"text"},"source":["The **pickle** module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file) is converted back into an object."]},{"cell_type":"code","metadata":{"id":"Xe1HSvNCZR58","colab_type":"code","colab":{}},"source":["import pickle\n","\n","train_latent = pickle.load(open('train_latent.p', 'rb')).drop(['SongID', 'UserID'], axis = 1)\n","test_latent = pickle.load(open('test_latent.p', 'rb')).drop(['SongID', 'UserID'], axis = 1)\n","\n","Xtrain = train_latent[train_latent.columns[train_latent.columns != 'target']]\n","Ytrain = train_latent.target.values\n","del(train_latent)\n","print('Shape of Xtrain: ', Xtrain.shape)\n","\n","Xtest = test_latent[test_latent.columns[test_latent.columns != 'target']]\n","Ytest = test_latent.target.values\n","del(test_latent)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YzLlLVkv5vfq","colab_type":"text"},"source":["## TensorFlow\n","**TensorFlow** is an end-to-end open-source platform to run machine learning models. It has been developped by Google.\n","\n","**Dense** implements the operation: $output = activation(input \\cdot kernel) + bias)$ where $activation$ is the element-wise activation function, $kernel$ is a weights matrix created by the layer, and $bias$ is a bias vector created by the layer. Here, we chose in most of cases $activation=tf.nn.relu$, which corresponds to $max(features, 0)$. We also have $activation=tf.nn.softmax$, whith $softmax$ defined like this: $\\frac{exp(inputs)}{\\sum exp(inputs)}$\n","\n","**Dropout** is used to drop data out.\n","\n","**to_categorical** is used to converts a class vector (integers) into binary class matrix."]},{"cell_type":"code","metadata":{"id":"t1TUaLxo76s_","colab_type":"code","outputId":"6504ba0f-95c6-4b4f-a2da-71435273ab54","colab":{"base_uri":"https://localhost:8080/","height":591}},"source":["import tensorflow as tf\n","\n","with tf.device('/gpu:0'): #run code on GPU\n","  #define the shape of the inputs\n","  model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(128, )),\n","        #tf.keras.layers.Dropout(0.20),\n","        tf.keras.layers.Dense(350, activation = tf.nn.relu),\n","        #tf.keras.layers.Dropout(0.18),\n","        tf.keras.layers.Dense(200, activation = tf.nn.relu),\n","        #tf.keras.layers.Dropout(0.18),\n","        tf.keras.layers.Dense(130, activation = tf.nn.relu),\n","        #tf.keras.layers.Dropout(0.12),\n","  ])\n","\n","  #compile model\n","  model.compile(optimizer = 'adam', \n","          loss = 'binary_crossentropy',\n","          metrics = ['accuracy'])\n","\n","  # use the model:\n","  #Y_test = to_categorical(Y_test)\n","  #Y_train = to_categorical(Y_train)\n","\n","  history = model.fit(Xtrain, Ytrain, epochs = 70, batch_size = 10000, validation_data = [Xtest,Ytest])\n","  loss,accuracy = model.evaluate(Xtest, Ytest)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 5901934 samples, validate on 1437031 samples\n","Epoch 1/70\n","5901934/5901934 [==============================] - 25s 4us/sample - loss: 7.6127 - acc: 0.5035 - val_loss: 7.5188 - val_acc: 0.5069\n","Epoch 2/70\n","5901934/5901934 [==============================] - 23s 4us/sample - loss: 7.6127 - acc: 0.5035 - val_loss: 7.5188 - val_acc: 0.5069\n","Epoch 3/70\n","5901934/5901934 [==============================] - 24s 4us/sample - loss: 7.6127 - acc: 0.5035 - val_loss: 7.5188 - val_acc: 0.5069\n","Epoch 4/70\n","5901934/5901934 [==============================] - 23s 4us/sample - loss: 7.6127 - acc: 0.5035 - val_loss: 7.5188 - val_acc: 0.5069\n","Epoch 5/70\n","4930000/5901934 [========================>.....] - ETA: 3s - loss: 7.6140 - acc: 0.5034"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-b19cd65c7890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;31m#Y_train =to_categorical(Y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m               \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m               \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m               \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     return [\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     return [\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"Hx1i0N-S-1u_","colab_type":"text"},"source":["## XGBoost\n","Considering the results we obtained in the previous section, we want to use a boosting algorithm, such as **XGBoost**. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting.\n","\n","The algorithm uses DMatrix for its calculations. This format is optimized for XGBoost.\n","\n","Before running XGBoost, we must set three types of parameters: general parameters, booster parameters and learning task parameters.\n","\n","*  General parameters relate to which booster we are using, commonly tree or linear model\n","\n","*   Booster parameters depend on which booster you have chosen\n","\n","*   Learning task parameters decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n"]},{"cell_type":"code","metadata":{"id":"H07FfBZ6cxrc","colab_type":"code","colab":{}},"source":["import xgboost as xgb\n","from xgboost import XGBClassifier\n","import numpy as np\n","\n","dtrain = xgb.DMatrix(Xtrain, Ytrain)\n","dtest = xgb.DMatrix(Xtest, Ytest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMg5nBHnYl7d","colab_type":"code","outputId":"a82d1edb-9ded-449e-ce75-1c7d3cdad9d4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["params = {\"objective\": \"binary:hinge\",\n","          \"colsample_bytree\": 0.3,\n","          \"learning_rate\": 0.1,\n","          \"max_depth\": 8,\n","          \"alpha\": 1,\n","          \"tree_method\": \"gpu_hist\",\n","          \"subsample\": 0.5,\n","          \"verbosity\": 2}\n","\n","num_round = 400\n","progress = dict()\n","evals = [(dtrain, \"train\"), (dtest, \"test\")]\n","\n","xgb.train(params, dtrain, num_boost_round = num_round, evals = evals, evals_result = progress)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0]\ttrain-error:0.496486\ttest-error:0.493062\n","[1]\ttrain-error:0.496486\ttest-error:0.493062\n","[2]\ttrain-error:0.496486\ttest-error:0.493062\n","[3]\ttrain-error:0.496486\ttest-error:0.493062\n","[4]\ttrain-error:0.496486\ttest-error:0.493062\n","[5]\ttrain-error:0.468685\ttest-error:0.486445\n","[6]\ttrain-error:0.467436\ttest-error:0.486121\n","[7]\ttrain-error:0.466835\ttest-error:0.485996\n","[8]\ttrain-error:0.466544\ttest-error:0.485934\n","[9]\ttrain-error:0.466447\ttest-error:0.485912\n","[10]\ttrain-error:0.465387\ttest-error:0.485909\n","[11]\ttrain-error:0.46431\ttest-error:0.485903\n","[12]\ttrain-error:0.462653\ttest-error:0.486672\n","[13]\ttrain-error:0.461096\ttest-error:0.486968\n","[14]\ttrain-error:0.459195\ttest-error:0.486963\n","[15]\ttrain-error:0.457136\ttest-error:0.486995\n","[16]\ttrain-error:0.454461\ttest-error:0.486482\n","[17]\ttrain-error:0.452506\ttest-error:0.486429\n","[18]\ttrain-error:0.450572\ttest-error:0.485891\n","[19]\ttrain-error:0.448511\ttest-error:0.485491\n","[20]\ttrain-error:0.446672\ttest-error:0.484796\n","[21]\ttrain-error:0.44423\ttest-error:0.484031\n","[22]\ttrain-error:0.4414\ttest-error:0.483022\n","[23]\ttrain-error:0.437973\ttest-error:0.481962\n","[24]\ttrain-error:0.434721\ttest-error:0.480944\n","[25]\ttrain-error:0.430758\ttest-error:0.479485\n","[26]\ttrain-error:0.426435\ttest-error:0.477908\n","[27]\ttrain-error:0.422881\ttest-error:0.476443\n","[28]\ttrain-error:0.41907\ttest-error:0.474901\n","[29]\ttrain-error:0.415126\ttest-error:0.473576\n","[30]\ttrain-error:0.410308\ttest-error:0.47189\n","[31]\ttrain-error:0.406334\ttest-error:0.47044\n","[32]\ttrain-error:0.402437\ttest-error:0.469213\n","[33]\ttrain-error:0.3989\ttest-error:0.468461\n","[34]\ttrain-error:0.395748\ttest-error:0.467297\n","[35]\ttrain-error:0.391815\ttest-error:0.465637\n","[36]\ttrain-error:0.388456\ttest-error:0.464888\n","[37]\ttrain-error:0.385912\ttest-error:0.463872\n","[38]\ttrain-error:0.383018\ttest-error:0.462565\n","[39]\ttrain-error:0.379959\ttest-error:0.461609\n","[40]\ttrain-error:0.377454\ttest-error:0.461019\n","[41]\ttrain-error:0.37486\ttest-error:0.460054\n","[42]\ttrain-error:0.372241\ttest-error:0.459336\n","[43]\ttrain-error:0.369969\ttest-error:0.458458\n","[44]\ttrain-error:0.368098\ttest-error:0.457529\n","[45]\ttrain-error:0.365861\ttest-error:0.456629\n","[46]\ttrain-error:0.364121\ttest-error:0.45593\n","[47]\ttrain-error:0.362279\ttest-error:0.455374\n","[48]\ttrain-error:0.36046\ttest-error:0.454635\n","[49]\ttrain-error:0.35849\ttest-error:0.453904\n","[50]\ttrain-error:0.357086\ttest-error:0.453057\n","[51]\ttrain-error:0.355339\ttest-error:0.452643\n","[52]\ttrain-error:0.353748\ttest-error:0.451868\n","[53]\ttrain-error:0.352405\ttest-error:0.451577\n","[54]\ttrain-error:0.351232\ttest-error:0.451105\n","[55]\ttrain-error:0.349795\ttest-error:0.450627\n","[56]\ttrain-error:0.348754\ttest-error:0.449994\n","[57]\ttrain-error:0.347503\ttest-error:0.449724\n","[58]\ttrain-error:0.346283\ttest-error:0.449504\n","[59]\ttrain-error:0.345126\ttest-error:0.44899\n","[60]\ttrain-error:0.343881\ttest-error:0.448626\n","[61]\ttrain-error:0.342744\ttest-error:0.448174\n","[62]\ttrain-error:0.341562\ttest-error:0.447788\n","[63]\ttrain-error:0.340533\ttest-error:0.447452\n","[64]\ttrain-error:0.339623\ttest-error:0.447161\n","[65]\ttrain-error:0.338702\ttest-error:0.447033\n","[66]\ttrain-error:0.337839\ttest-error:0.446854\n","[67]\ttrain-error:0.336828\ttest-error:0.446481\n","[68]\ttrain-error:0.335884\ttest-error:0.446395\n","[69]\ttrain-error:0.335038\ttest-error:0.445979\n","[70]\ttrain-error:0.334277\ttest-error:0.445645\n","[71]\ttrain-error:0.333543\ttest-error:0.445643\n","[72]\ttrain-error:0.332811\ttest-error:0.445505\n","[73]\ttrain-error:0.332094\ttest-error:0.445658\n","[74]\ttrain-error:0.331479\ttest-error:0.445498\n","[75]\ttrain-error:0.330981\ttest-error:0.445482\n","[76]\ttrain-error:0.330383\ttest-error:0.445404\n","[77]\ttrain-error:0.329677\ttest-error:0.445144\n","[78]\ttrain-error:0.329014\ttest-error:0.44494\n","[79]\ttrain-error:0.328396\ttest-error:0.444592\n","[80]\ttrain-error:0.327737\ttest-error:0.444416\n","[81]\ttrain-error:0.32717\ttest-error:0.444501\n","[82]\ttrain-error:0.326666\ttest-error:0.444422\n","[83]\ttrain-error:0.32606\ttest-error:0.444386\n","[84]\ttrain-error:0.325623\ttest-error:0.444255\n","[85]\ttrain-error:0.325078\ttest-error:0.444182\n","[86]\ttrain-error:0.324521\ttest-error:0.444034\n","[87]\ttrain-error:0.323969\ttest-error:0.444137\n","[88]\ttrain-error:0.323508\ttest-error:0.443867\n","[89]\ttrain-error:0.322899\ttest-error:0.44391\n","[90]\ttrain-error:0.322507\ttest-error:0.443942\n","[91]\ttrain-error:0.322023\ttest-error:0.443921\n","[92]\ttrain-error:0.321603\ttest-error:0.443752\n","[93]\ttrain-error:0.321008\ttest-error:0.443675\n","[94]\ttrain-error:0.320576\ttest-error:0.443602\n","[95]\ttrain-error:0.320057\ttest-error:0.443377\n","[96]\ttrain-error:0.319577\ttest-error:0.443466\n","[97]\ttrain-error:0.319276\ttest-error:0.443574\n","[98]\ttrain-error:0.318775\ttest-error:0.443471\n","[99]\ttrain-error:0.318257\ttest-error:0.443596\n","[100]\ttrain-error:0.317806\ttest-error:0.4437\n","[101]\ttrain-error:0.317265\ttest-error:0.4437\n","[102]\ttrain-error:0.316951\ttest-error:0.443718\n","[103]\ttrain-error:0.316497\ttest-error:0.443603\n","[104]\ttrain-error:0.316076\ttest-error:0.443936\n","[105]\ttrain-error:0.315719\ttest-error:0.443854\n","[106]\ttrain-error:0.315177\ttest-error:0.443661\n","[107]\ttrain-error:0.314836\ttest-error:0.443799\n","[108]\ttrain-error:0.314578\ttest-error:0.44361\n","[109]\ttrain-error:0.314127\ttest-error:0.443768\n","[110]\ttrain-error:0.31369\ttest-error:0.443824\n","[111]\ttrain-error:0.313354\ttest-error:0.443739\n","[112]\ttrain-error:0.312997\ttest-error:0.443688\n","[113]\ttrain-error:0.312639\ttest-error:0.443699\n","[114]\ttrain-error:0.312207\ttest-error:0.443657\n","[115]\ttrain-error:0.311675\ttest-error:0.443949\n","[116]\ttrain-error:0.311322\ttest-error:0.443976\n","[117]\ttrain-error:0.310951\ttest-error:0.443942\n","[118]\ttrain-error:0.310573\ttest-error:0.443849\n","[119]\ttrain-error:0.310149\ttest-error:0.443964\n","[120]\ttrain-error:0.309773\ttest-error:0.443949\n","[121]\ttrain-error:0.309444\ttest-error:0.443878\n","[122]\ttrain-error:0.309089\ttest-error:0.443912\n","[123]\ttrain-error:0.308673\ttest-error:0.444084\n","[124]\ttrain-error:0.308379\ttest-error:0.444057\n","[125]\ttrain-error:0.308045\ttest-error:0.444272\n","[126]\ttrain-error:0.307857\ttest-error:0.444243\n","[127]\ttrain-error:0.307459\ttest-error:0.444261\n","[128]\ttrain-error:0.307121\ttest-error:0.444083\n","[129]\ttrain-error:0.306811\ttest-error:0.444244\n","[130]\ttrain-error:0.306465\ttest-error:0.444216\n","[131]\ttrain-error:0.306068\ttest-error:0.444256\n","[132]\ttrain-error:0.305732\ttest-error:0.444243\n","[133]\ttrain-error:0.305358\ttest-error:0.444171\n","[134]\ttrain-error:0.305023\ttest-error:0.444241\n","[135]\ttrain-error:0.304741\ttest-error:0.444283\n","[136]\ttrain-error:0.304408\ttest-error:0.44439\n","[137]\ttrain-error:0.304066\ttest-error:0.444313\n","[138]\ttrain-error:0.303723\ttest-error:0.444253\n","[139]\ttrain-error:0.303457\ttest-error:0.444223\n","[140]\ttrain-error:0.30324\ttest-error:0.444247\n","[141]\ttrain-error:0.303002\ttest-error:0.444253\n","[142]\ttrain-error:0.30273\ttest-error:0.444156\n","[143]\ttrain-error:0.302453\ttest-error:0.444297\n","[144]\ttrain-error:0.302091\ttest-error:0.44434\n","[145]\ttrain-error:0.301685\ttest-error:0.444424\n","[146]\ttrain-error:0.301435\ttest-error:0.444506\n","[147]\ttrain-error:0.301138\ttest-error:0.444522\n","[148]\ttrain-error:0.300943\ttest-error:0.44446\n","[149]\ttrain-error:0.300602\ttest-error:0.44459\n","[150]\ttrain-error:0.300289\ttest-error:0.444553\n","[151]\ttrain-error:0.299925\ttest-error:0.444565\n","[152]\ttrain-error:0.299558\ttest-error:0.444785\n","[153]\ttrain-error:0.299234\ttest-error:0.444745\n","[154]\ttrain-error:0.299007\ttest-error:0.444884\n","[155]\ttrain-error:0.298701\ttest-error:0.444981\n","[156]\ttrain-error:0.298391\ttest-error:0.44485\n","[157]\ttrain-error:0.298123\ttest-error:0.444793\n","[158]\ttrain-error:0.297886\ttest-error:0.444857\n","[159]\ttrain-error:0.297571\ttest-error:0.444867\n","[160]\ttrain-error:0.297387\ttest-error:0.444949\n","[161]\ttrain-error:0.297136\ttest-error:0.445023\n","[162]\ttrain-error:0.29692\ttest-error:0.445042\n","[163]\ttrain-error:0.296695\ttest-error:0.444997\n","[164]\ttrain-error:0.296439\ttest-error:0.445063\n","[165]\ttrain-error:0.296173\ttest-error:0.445303\n","[166]\ttrain-error:0.295987\ttest-error:0.445422\n","[167]\ttrain-error:0.295698\ttest-error:0.445711\n","[168]\ttrain-error:0.295466\ttest-error:0.445632\n","[169]\ttrain-error:0.295187\ttest-error:0.445484\n","[170]\ttrain-error:0.29496\ttest-error:0.445568\n","[171]\ttrain-error:0.294759\ttest-error:0.445452\n","[172]\ttrain-error:0.294484\ttest-error:0.445658\n","[173]\ttrain-error:0.294256\ttest-error:0.445587\n","[174]\ttrain-error:0.294029\ttest-error:0.445655\n","[175]\ttrain-error:0.293845\ttest-error:0.445599\n","[176]\ttrain-error:0.293646\ttest-error:0.445747\n","[177]\ttrain-error:0.293389\ttest-error:0.445859\n","[178]\ttrain-error:0.293159\ttest-error:0.445793\n","[179]\ttrain-error:0.292941\ttest-error:0.445726\n","[180]\ttrain-error:0.292653\ttest-error:0.445719\n","[181]\ttrain-error:0.292412\ttest-error:0.445642\n","[182]\ttrain-error:0.292293\ttest-error:0.445662\n","[183]\ttrain-error:0.292044\ttest-error:0.445654\n","[184]\ttrain-error:0.291797\ttest-error:0.445498\n","[185]\ttrain-error:0.291549\ttest-error:0.445632\n","[186]\ttrain-error:0.291344\ttest-error:0.445867\n","[187]\ttrain-error:0.291085\ttest-error:0.445768\n","[188]\ttrain-error:0.290835\ttest-error:0.445732\n","[189]\ttrain-error:0.29057\ttest-error:0.445847\n","[190]\ttrain-error:0.290371\ttest-error:0.446018\n","[191]\ttrain-error:0.290074\ttest-error:0.446027\n","[192]\ttrain-error:0.289951\ttest-error:0.446033\n","[193]\ttrain-error:0.289718\ttest-error:0.446082\n","[194]\ttrain-error:0.289482\ttest-error:0.44604\n","[195]\ttrain-error:0.289252\ttest-error:0.445821\n","[196]\ttrain-error:0.289025\ttest-error:0.445937\n","[197]\ttrain-error:0.288785\ttest-error:0.446214\n","[198]\ttrain-error:0.28861\ttest-error:0.446251\n","[199]\ttrain-error:0.288337\ttest-error:0.446267\n","[200]\ttrain-error:0.288103\ttest-error:0.446314\n","[201]\ttrain-error:0.287941\ttest-error:0.446169\n","[202]\ttrain-error:0.287681\ttest-error:0.446185\n","[203]\ttrain-error:0.287492\ttest-error:0.446421\n","[204]\ttrain-error:0.287337\ttest-error:0.446305\n","[205]\ttrain-error:0.287094\ttest-error:0.446349\n","[206]\ttrain-error:0.286905\ttest-error:0.446422\n","[207]\ttrain-error:0.28669\ttest-error:0.446343\n","[208]\ttrain-error:0.286449\ttest-error:0.446505\n","[209]\ttrain-error:0.286247\ttest-error:0.446393\n","[210]\ttrain-error:0.286039\ttest-error:0.446663\n","[211]\ttrain-error:0.285883\ttest-error:0.446549\n","[212]\ttrain-error:0.285677\ttest-error:0.446516\n","[213]\ttrain-error:0.285489\ttest-error:0.446415\n","[214]\ttrain-error:0.285285\ttest-error:0.446616\n","[215]\ttrain-error:0.285128\ttest-error:0.446788\n","[216]\ttrain-error:0.284959\ttest-error:0.446833\n","[217]\ttrain-error:0.284776\ttest-error:0.447067\n","[218]\ttrain-error:0.284534\ttest-error:0.446927\n","[219]\ttrain-error:0.284352\ttest-error:0.44691\n","[220]\ttrain-error:0.284132\ttest-error:0.447098\n","[221]\ttrain-error:0.283952\ttest-error:0.446916\n","[222]\ttrain-error:0.283783\ttest-error:0.447018\n","[223]\ttrain-error:0.283564\ttest-error:0.447067\n","[224]\ttrain-error:0.283362\ttest-error:0.447095\n","[225]\ttrain-error:0.283162\ttest-error:0.447122\n","[226]\ttrain-error:0.283013\ttest-error:0.447201\n","[227]\ttrain-error:0.282827\ttest-error:0.447212\n","[228]\ttrain-error:0.282632\ttest-error:0.447237\n","[229]\ttrain-error:0.282438\ttest-error:0.447239\n","[230]\ttrain-error:0.282293\ttest-error:0.44739\n","[231]\ttrain-error:0.282154\ttest-error:0.447349\n","[232]\ttrain-error:0.281944\ttest-error:0.447346\n","[233]\ttrain-error:0.281743\ttest-error:0.447414\n","[234]\ttrain-error:0.281595\ttest-error:0.447475\n","[235]\ttrain-error:0.281346\ttest-error:0.447551\n","[236]\ttrain-error:0.281212\ttest-error:0.4475\n","[237]\ttrain-error:0.281042\ttest-error:0.447544\n","[238]\ttrain-error:0.280907\ttest-error:0.447564\n","[239]\ttrain-error:0.280769\ttest-error:0.447489\n","[240]\ttrain-error:0.280576\ttest-error:0.447692\n","[241]\ttrain-error:0.280409\ttest-error:0.447675\n","[242]\ttrain-error:0.280235\ttest-error:0.44772\n","[243]\ttrain-error:0.280071\ttest-error:0.447618\n","[244]\ttrain-error:0.279924\ttest-error:0.44759\n","[245]\ttrain-error:0.279717\ttest-error:0.44754\n","[246]\ttrain-error:0.279545\ttest-error:0.447622\n","[247]\ttrain-error:0.279381\ttest-error:0.447608\n","[248]\ttrain-error:0.279253\ttest-error:0.447647\n","[249]\ttrain-error:0.279079\ttest-error:0.447825\n","[250]\ttrain-error:0.27894\ttest-error:0.447824\n","[251]\ttrain-error:0.278773\ttest-error:0.447764\n","[252]\ttrain-error:0.278563\ttest-error:0.447857\n","[253]\ttrain-error:0.278426\ttest-error:0.447911\n","[254]\ttrain-error:0.278287\ttest-error:0.448334\n","[255]\ttrain-error:0.278061\ttest-error:0.448292\n","[256]\ttrain-error:0.277911\ttest-error:0.447862\n","[257]\ttrain-error:0.277772\ttest-error:0.448213\n","[258]\ttrain-error:0.277576\ttest-error:0.448226\n","[259]\ttrain-error:0.277453\ttest-error:0.44786\n","[260]\ttrain-error:0.27731\ttest-error:0.447965\n","[261]\ttrain-error:0.27719\ttest-error:0.447962\n","[262]\ttrain-error:0.277024\ttest-error:0.447929\n","[263]\ttrain-error:0.276832\ttest-error:0.447949\n","[264]\ttrain-error:0.27663\ttest-error:0.447958\n","[265]\ttrain-error:0.27653\ttest-error:0.447966\n","[266]\ttrain-error:0.276334\ttest-error:0.447925\n","[267]\ttrain-error:0.276137\ttest-error:0.447949\n","[268]\ttrain-error:0.275968\ttest-error:0.448015\n","[269]\ttrain-error:0.275779\ttest-error:0.447959\n","[270]\ttrain-error:0.275636\ttest-error:0.448756\n","[271]\ttrain-error:0.275473\ttest-error:0.448933\n","[272]\ttrain-error:0.275255\ttest-error:0.448887\n","[273]\ttrain-error:0.27513\ttest-error:0.449789\n","[274]\ttrain-error:0.275002\ttest-error:0.449866\n","[275]\ttrain-error:0.274867\ttest-error:0.449939\n","[276]\ttrain-error:0.274687\ttest-error:0.449758\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9032db3a7e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"TYEHKWRMAmf6","colab_type":"text"},"source":["We can conclude that this method is not efficient because the test error is very high and doesn't decrease with a growing number of iterations."]},{"cell_type":"markdown","metadata":{"id":"yTWcxG4bBD4a","colab_type":"text"},"source":["Let's apply XGBoost to a Random Forest method."]},{"cell_type":"code","metadata":{"id":"Tmph72kkjeRv","colab_type":"code","outputId":"2874749b-d9a3-44ef-e705-fd8322d28657","colab":{"base_uri":"https://localhost:8080/","height":684}},"source":["params = {\n","  \"colsample_bynode\": 0.8,\n","  \"learning_rate\": 1,\n","  \"max_depth\": 5,\n","  \"num_parallel_tree\": 100,\n","  \"objective\": \"binary:logistic\",\n","  \"subsample\": 0.8,\n","  \"tree_method\": \"gpu_hist\",\n","  \"verbosity\": 2\n","}\n","num_round = 400\n","progress = dict()\n","evals = [(dtrain,\"train\"),(dtest,\"test\")]\n","\n","xgb.train(params, dtrain, num_boost_round = num_round, evals = evals, evals_result = progress)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0]\ttrain-error:0.383622\ttest-error:0.454578\n","[1]\ttrain-error:0.366298\ttest-error:0.454279\n","[2]\ttrain-error:0.353478\ttest-error:0.4538\n","[3]\ttrain-error:0.344892\ttest-error:0.453893\n","[4]\ttrain-error:0.337752\ttest-error:0.454109\n","[5]\ttrain-error:0.33106\ttest-error:0.453443\n","[6]\ttrain-error:0.326056\ttest-error:0.453495\n","[7]\ttrain-error:0.321501\ttest-error:0.453083\n","[8]\ttrain-error:0.318183\ttest-error:0.453429\n","[9]\ttrain-error:0.314604\ttest-error:0.453642\n","[10]\ttrain-error:0.311081\ttest-error:0.453516\n","[11]\ttrain-error:0.308149\ttest-error:0.454333\n","[12]\ttrain-error:0.306125\ttest-error:0.453643\n","[13]\ttrain-error:0.303332\ttest-error:0.454323\n","[14]\ttrain-error:0.300684\ttest-error:0.454157\n","[15]\ttrain-error:0.298673\ttest-error:0.4543\n","[16]\ttrain-error:0.296385\ttest-error:0.454443\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2a07b865a2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vs7nOj2a8TUH","colab_type":"code","colab":{}},"source":["params = {\n","  'booster':'gblinear'\n","}\n","num_round = 400\n","progress = dict()\n","evals = [(dtrain, \"train\"), (dtest, \"test\")]\n","\n","xgb.train(params, dtrain, num_boost_round = num_round, evals = evals, evals_result = progress)"],"execution_count":0,"outputs":[]}]}